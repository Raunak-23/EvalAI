{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raunak-23/EvalAI/blob/main/ocr_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xK4mF975r2H",
        "outputId": "4ada2a0a-8d73-42c2-d101-d565eb110aed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rn8BlkEcudBk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "from os import walk\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from skimage.feature import local_binary_pattern\n",
        "from skimage.measure import find_contours\n",
        "from skimage.morphology import binary_dilation\n",
        "from sklearn.svm import SVC\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import TensorDataset\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPmn5wsa55NA"
      },
      "outputs": [],
      "source": [
        "# Parameters and constants\n",
        "AVAILABLE_WRITERS = 672\n",
        "RESULTS_FILE = 'results.txt'\n",
        "TIME_FILE = 'time.txt'\n",
        "OVERLAPPING_METHOD = 0\n",
        "LINES_METHOD = 1\n",
        "SUPPORT_VECTOR_CLASSIFIER = 0\n",
        "NEURAL_NETWORK_CLASSIFIER = 1\n",
        "HISTOGRAM_BINS = 256\n",
        "NN_LEARNING_RATE = 0.003\n",
        "NN_WEIGHT_DECAY = 0.01\n",
        "NN_DROPOUT = 0.25\n",
        "NN_EPOCHS = 200\n",
        "NN_BATCH_SIZE = 16\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjAZejbo59kE"
      },
      "outputs": [],
      "source": [
        "def show_images(images, titles=None):\n",
        "    n_ims = len(images)\n",
        "    if titles is None:\n",
        "        titles = ['(%d)' % i for i in range(1, n_ims + 1)]\n",
        "    fig = plt.figure()\n",
        "    n = 1\n",
        "    for image, title in zip(images, titles):\n",
        "        a = fig.add_subplot(1, n_ims, n)\n",
        "        if image.ndim == 2:\n",
        "            plt.gray()\n",
        "        plt.imshow(image)\n",
        "        a.set_title(title)\n",
        "        n += 1\n",
        "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CB0o2S946DZl"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(img, feature_extraction_method=OVERLAPPING_METHOD):\n",
        "    if feature_extraction_method == OVERLAPPING_METHOD:\n",
        "        img_copy = img.copy()\n",
        "        if len(img.shape) > 2:\n",
        "            img_copy = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\n",
        "        img_copy = cv2.medianBlur(img_copy, 5)\n",
        "        img_copy = cv2.threshold(img_copy, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "        min_vertical, max_vertical = get_corpus_boundaries(img_copy)\n",
        "        img_copy = img_copy[min_vertical:max_vertical]\n",
        "        return img_copy\n",
        "\n",
        "    if feature_extraction_method == LINES_METHOD:\n",
        "        img_copy = img.copy()\n",
        "        if len(img.shape) > 2:\n",
        "            grayscale_img = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\n",
        "        else:\n",
        "            grayscale_img = img.copy()\n",
        "        img_copy = cv2.threshold(grayscale_img, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "        min_vertical, max_vertical = get_corpus_boundaries(img_copy)\n",
        "        img_copy = img_copy[min_vertical:max_vertical]\n",
        "        grayscale_img = grayscale_img[min_vertical:max_vertical]\n",
        "        filter_kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
        "        img_copy_sharpened = cv2.filter2D(img_copy, -1, filter_kernel)\n",
        "        return img_copy_sharpened, grayscale_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZNT2Ygf6HLh"
      },
      "outputs": [],
      "source": [
        "def get_corpus_boundaries(img):\n",
        "    crop = []\n",
        "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (100, 1))\n",
        "    detect_horizontal = cv2.morphologyEx(img, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)\n",
        "    contours = cv2.findContours(detect_horizontal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "    prev = -1\n",
        "    for i, c in enumerate(contours):\n",
        "        if np.abs(prev - int(c[0][0][1])) > 800 or prev == -1:\n",
        "            crop.append(int(c[0][0][1]))\n",
        "            prev = int(c[0][0][1])\n",
        "    crop.sort()\n",
        "    max_vertical = crop[1] - 20\n",
        "    min_vertical = crop[0] + 20\n",
        "    return min_vertical, max_vertical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjjkaUsA6JxF"
      },
      "outputs": [],
      "source": [
        "def segment_image(img, num, grayscale_img=None):\n",
        "    if grayscale_img is not None:\n",
        "        grayscale_images = []\n",
        "        img_copy = np.copy(img)\n",
        "        kernel = np.ones((1, num))\n",
        "        img_copy = binary_dilation(img_copy, kernel)\n",
        "        bounding_boxes = find_contours(img_copy, 0.8)\n",
        "        for box in bounding_boxes:\n",
        "            x_min = int(np.min(box[:, 1]))\n",
        "            x_max = int(np.max(box[:, 1]))\n",
        "            y_min = int(np.min(box[:, 0]))\n",
        "            y_max = int(np.max(box[:, 0]))\n",
        "            if (y_max - y_min) > 50 and (x_max - x_min) > 50:\n",
        "                grayscale_images.append(grayscale_img[y_min:y_max, x_min:x_max])\n",
        "        return grayscale_images\n",
        "    images = []\n",
        "    img_copy = np.copy(img)\n",
        "    kernel = np.ones((1, num))\n",
        "    img_copy = binary_dilation(img_copy, kernel)\n",
        "    bounding_boxes = find_contours(img_copy, 0.8)\n",
        "    for box in bounding_boxes:\n",
        "        x_min = int(np.min(box[:, 1]))\n",
        "        x_max = int(np.max(box[:, 1]))\n",
        "        y_min = int(np.min(box[:, 0]))\n",
        "        y_max = int(np.max(box[:, 0]))\n",
        "        if (y_max - y_min) > 10 and (x_max - x_min) > 10:\n",
        "            images.append(img[y_min:y_max, x_min:x_max])\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpLMzhNm6OK-"
      },
      "outputs": [],
      "source": [
        "def overlap_words(words, avg_height):\n",
        "    overlapped_img = np.zeros((3600, 320))\n",
        "    index_i = 0\n",
        "    index_j = 0\n",
        "    max_height = 0\n",
        "    for word in words:\n",
        "        if word.shape[1] + index_j > overlapped_img.shape[1]:\n",
        "            max_height = 0\n",
        "            index_j = 0\n",
        "            index_i += int(avg_height // 2)\n",
        "        if word.shape[1] < overlapped_img.shape[1] and word.shape[0] < overlapped_img.shape[0]:\n",
        "            indices = np.copy(overlapped_img[index_i:index_i + word.shape[0], index_j:index_j + word.shape[1]])\n",
        "            indices = np.maximum(indices, word)\n",
        "            overlapped_img[index_i:index_i + word.shape[0], index_j:index_j + word.shape[1]] = indices\n",
        "            index_j += word.shape[1]\n",
        "            if max_height < word.shape[0]:\n",
        "                max_height = word.shape[0]\n",
        "    overlapped_img = overlapped_img[:index_i + int(avg_height // 2), :]\n",
        "    return overlapped_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TvnTEKb6Q7t"
      },
      "outputs": [],
      "source": [
        "def get_textures(image):\n",
        "    index_i = 0\n",
        "    index_j = 0\n",
        "    texture_size = 100\n",
        "    textures = []\n",
        "    while index_i + texture_size < image.shape[0]:\n",
        "        if index_j + texture_size > image.shape[1]:\n",
        "            index_j = 0\n",
        "            index_i += texture_size\n",
        "        textures.append(np.copy(image[index_i: index_i + texture_size, index_j: index_j + texture_size]))\n",
        "        index_j += texture_size\n",
        "    return textures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xDpeLw06USy"
      },
      "outputs": [],
      "source": [
        "def model_generator(features, labels, feature_extraction_method=OVERLAPPING_METHOD,\n",
        "                    classifier_type=SUPPORT_VECTOR_CLASSIFIER):\n",
        "    histograms = []\n",
        "\n",
        "    if feature_extraction_method == OVERLAPPING_METHOD:\n",
        "        for texture_array in features:\n",
        "            for texture in texture_array:\n",
        "                lbp = local_binary_pattern(texture, 8, 3, 'default')\n",
        "                histogram, _ = np.histogram(lbp, density=False, bins=HISTOGRAM_BINS, range=(0, HISTOGRAM_BINS))\n",
        "                histograms.append(histogram)\n",
        "\n",
        "    elif feature_extraction_method == LINES_METHOD:\n",
        "        for line in features:\n",
        "            lbp = local_binary_pattern(line, 8, 3, 'default')\n",
        "            histogram, _ = np.histogram(lbp, density=False, bins=HISTOGRAM_BINS, range=(0, HISTOGRAM_BINS))\n",
        "            histograms.append(histogram)\n",
        "\n",
        "    if classifier_type == SUPPORT_VECTOR_CLASSIFIER:\n",
        "        model = SVC(kernel='linear')\n",
        "        model.fit(histograms, labels)\n",
        "        return model\n",
        "\n",
        "    if classifier_type == NEURAL_NETWORK_CLASSIFIER:\n",
        "        model = nn.Sequential(nn.Linear(HISTOGRAM_BINS, 128),\n",
        "                              nn.ReLU(),\n",
        "                              nn.Dropout(p=NN_DROPOUT),\n",
        "                              nn.Linear(128, 64),\n",
        "                              nn.ReLU(),\n",
        "                              nn.Dropout(p=NN_DROPOUT),\n",
        "                              nn.Linear(64, 3))\n",
        "        model.to(DEVICE)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adamax(model.parameters(), lr=NN_LEARNING_RATE, weight_decay=NN_WEIGHT_DECAY)\n",
        "        inputs = torch.Tensor(histograms)\n",
        "        labels = torch.tensor(labels, dtype=torch.long) - 1\n",
        "        dataset = TensorDataset(inputs, labels)\n",
        "        train_loader = torch.utils.data.DataLoader(dataset, batch_size=NN_BATCH_SIZE, shuffle=True)\n",
        "        for epoch in range(NN_EPOCHS):\n",
        "            for inputs, labels in train_loader:\n",
        "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "                output = model(inputs)\n",
        "                loss = criterion(output, labels)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjF4c-jx6Yj8"
      },
      "outputs": [],
      "source": [
        "def predict(model, test_image, feature_extraction_method=OVERLAPPING_METHOD, classifier_type=SUPPORT_VECTOR_CLASSIFIER):\n",
        "    if feature_extraction_method == OVERLAPPING_METHOD:\n",
        "        img = preprocess_image(test_image)\n",
        "        words = segment_image(img, 3)\n",
        "        avg_height = 0\n",
        "        for word in words:\n",
        "            avg_height += word.shape[0] / len(words)\n",
        "        overlapped_img = overlap_words(words, avg_height)\n",
        "        textures = get_textures(overlapped_img)\n",
        "        prediction = np.zeros(4)\n",
        "        for texture in textures:\n",
        "            lbp = local_binary_pattern(texture, 8, 3, 'default')\n",
        "            histogram, _ = np.histogram(lbp, density=False, bins=HISTOGRAM_BINS, range=(0, HISTOGRAM_BINS))\n",
        "            if classifier_type == SUPPORT_VECTOR_CLASSIFIER:\n",
        "                prediction[model.predict([histogram])] += 1\n",
        "            if classifier_type == NEURAL_NETWORK_CLASSIFIER:\n",
        "                with torch.no_grad():\n",
        "                    model.eval()\n",
        "                    histogram = torch.Tensor(histogram)\n",
        "                    probabilities = F.softmax(model.forward(histogram), dim=0)\n",
        "                    _, top_class = probabilities.topk(1)\n",
        "                    prediction[top_class + 1] += 1\n",
        "        return np.argmax(prediction)\n",
        "\n",
        "    if feature_extraction_method == LINES_METHOD:\n",
        "        img, grayscale_img = preprocess_image(test_image, feature_extraction_method)\n",
        "        grayscale_lines = segment_image(img, 100, grayscale_img)\n",
        "        prediction = np.zeros(4)\n",
        "        for line in grayscale_lines:\n",
        "            lbp = local_binary_pattern(line, 8, 3, 'default')\n",
        "            histogram, _ = np.histogram(lbp, density=False, bins=HISTOGRAM_BINS, range=(0, HISTOGRAM_BINS))\n",
        "            if classifier_type == SUPPORT_VECTOR_CLASSIFIER:\n",
        "                prediction[model.predict([histogram])] += 1\n",
        "            if classifier_type == NEURAL_NETWORK_CLASSIFIER:\n",
        "                with torch.no_grad():\n",
        "                    model.eval()\n",
        "                    histogram = torch.Tensor(histogram)\n",
        "                    probabilities = F.softmax(model.forward(histogram), dim=0)\n",
        "                    _, top_class = probabilities.topk(1)\n",
        "                    prediction[top_class + 1] += 1\n",
        "        return np.argmax(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eun5u0m6e5J"
      },
      "outputs": [],
      "source": [
        "def read_random_images(root):\n",
        "    images = []\n",
        "    labels = []\n",
        "    test_images = []\n",
        "    test_labels = []\n",
        "    for i in range(3):\n",
        "        found_images = False\n",
        "        while not found_images:\n",
        "            images_path = root\n",
        "            random_writer = random.randrange(AVAILABLE_WRITERS)\n",
        "            if random_writer < 10:\n",
        "                random_writer = \"00\" + str(random_writer)\n",
        "            elif random_writer < 100:\n",
        "                random_writer = \"0\" + str(random_writer)\n",
        "            images_path = os.path.join(images_path, str(random_writer))\n",
        "            if not os.path.isdir(images_path):\n",
        "                continue\n",
        "            _, _, filenames = next(walk(images_path))\n",
        "            if len(filenames) <= 2 and i == 2 and len(test_images) == 0:\n",
        "                continue\n",
        "            if len(filenames) >= 2:\n",
        "                found_images = True\n",
        "                chosen_filenames = []\n",
        "                for j in range(2):\n",
        "                    random_filename = random.choice(filenames)\n",
        "                    while random_filename in chosen_filenames:\n",
        "                        random_filename = random.choice(filenames)\n",
        "                    chosen_filenames.append(random_filename)\n",
        "                    images.append(cv2.imread(os.path.join(images_path, random_filename)))\n",
        "                    labels.append(i + 1)\n",
        "                if len(filenames) >= 3:\n",
        "                    random_filename = random.choice(filenames)\n",
        "                    while random_filename in chosen_filenames:\n",
        "                        random_filename = random.choice(filenames)\n",
        "                    chosen_filenames.append(random_filename)\n",
        "                    test_images.append(cv2.imread(os.path.join(images_path, random_filename)))\n",
        "                    test_labels.append(i + 1)\n",
        "    test_choice = random.randint(0, len(test_images) - 1)\n",
        "    test_image = test_images[test_choice]\n",
        "    test_label = test_labels[test_choice]\n",
        "    return images, labels, test_image, test_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoZMj4CT6gFd"
      },
      "outputs": [],
      "source": [
        "def extract_features(images, labels, feature_extraction_method=OVERLAPPING_METHOD):\n",
        "    if feature_extraction_method == LINES_METHOD:\n",
        "        lines_labels = []\n",
        "        lines = []\n",
        "        for image, label in zip(images, labels):\n",
        "            image, grayscale_image = preprocess_image(image, feature_extraction_method)\n",
        "            grayscale_lines = segment_image(image, 100, grayscale_image)\n",
        "            for line in grayscale_lines:\n",
        "                lines.append(line)\n",
        "                lines_labels.append(label)\n",
        "        return lines, lines_labels\n",
        "\n",
        "    if feature_extraction_method == OVERLAPPING_METHOD:\n",
        "        textures = []\n",
        "        textures_labels = []\n",
        "        for image, label in zip(images, labels):\n",
        "            image = preprocess_image(image)\n",
        "            words = segment_image(image, 3)\n",
        "            avg_height = 0\n",
        "            for word in words:\n",
        "                avg_height += word.shape[0] / len(words)\n",
        "            overlapped_img = overlap_words(words, avg_height)\n",
        "            new_textures = get_textures(overlapped_img)\n",
        "            textures.append(new_textures)\n",
        "            for j in range(len(new_textures)):\n",
        "                textures_labels.append(label)\n",
        "        return textures, textures_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAqM5GzS6k4s",
        "outputId": "0dec6f7f-bb37-4de1-ce5f-f6d303a3937f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccd3c81e",
        "outputId": "791e5db8-22f7-4a87-b894-f4d69d9f0fef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/naderabdalghani/iam-handwritten-forms-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.31G/4.31G [00:52<00:00, 88.9MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/naderabdalghani/iam-handwritten-forms-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"naderabdalghani/iam-handwritten-forms-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "SjPrHfFA6pNU",
        "outputId": "aa1a9a64-e6b1-4b1b-9dee-d4752de21162"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'OVERLAPPING_METHOD' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1413864209.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/data/iam_words/words/a01/a01-000u\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfeature_extraction_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOVERLAPPING_METHOD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mclassifier_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSUPPORT_VECTOR_CLASSIFIER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcorrect_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'OVERLAPPING_METHOD' is not defined"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "root= \"/content/drive/MyDrive/data/iam_words/words/a01/a01-000u\"\n",
        "feature_extraction_method=OVERLAPPING_METHOD\n",
        "classifier_type=SUPPORT_VECTOR_CLASSIFIER\n",
        "correct_predictions = 0\n",
        "total_execution_time = 0\n",
        "for epoch in range(epochs):\n",
        "    images, labels, test_image, test_label = read_random_images(root)\n",
        "    start_time = time.time()\n",
        "    features, features_labels = extract_features(images, labels, feature_extraction_method)\n",
        "    model = model_generator(features, features_labels, feature_extraction_method, classifier_type)\n",
        "    prediction = predict(model, test_image, feature_extraction_method, classifier_type)\n",
        "    execution_time = time.time() - start_time\n",
        "    total_execution_time += execution_time\n",
        "    if prediction == test_label:\n",
        "        correct_predictions += 1\n",
        "    print(\"Epoch #{} | Execution time {} seconds | Model accuracy {}\".format(epoch + 1, round(execution_time, 2), round((correct_predictions / (epoch + 1)) * 100, 2)))\n",
        "print(\"Model accuracy = {}% using {} sample tests.\".format((correct_predictions / epochs) * 100, epochs))\n",
        "print(\"Total execution time = {} using {} sample tests.\".format(round(total_execution_time, 2), epochs))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "history_visible": true,
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
